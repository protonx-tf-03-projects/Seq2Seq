{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainSeq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a7tDIjLP3qW"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt2jkVwiX5bC",
        "outputId": "b4c5219c-47cd-4ad6-c9aa-05486ba1f234"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  3 06:49:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqC_yVxZ4qje",
        "outputId": "01eacfed-aec3-4123-f5ad-b801de270f9b"
      },
      "source": [
        " %cd /content/\n",
        "\n",
        "!git clone --branch DucLinh_branch https://Xunino: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@github.com/protonx-tf-03-projects/Seq2Seq.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Seq2Seq'...\n",
            "remote: Enumerating objects: 712, done.\u001b[K\n",
            "remote: Counting objects: 100% (712/712), done.\u001b[K\n",
            "remote: Compressing objects: 100% (442/442), done.\u001b[K\n",
            "remote: Total 712 (delta 364), reused 512 (delta 188), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (712/712), 9.68 MiB | 13.92 MiB/s, done.\n",
            "Resolving deltas: 100% (364/364), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_LU-3lC4zJf",
        "outputId": "9a8ea970-2de8-4e63-8236-516aef9e091e"
      },
      "source": [
        "%cd Seq2Seq/\n",
        "\n",
        "inp_lang = \"./dataset/train.en.txt\"\n",
        "tar_lang = \"./dataset/train.vi.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Seq2Seq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq2idojIxQJ0"
      },
      "source": [
        "#Not use attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3FtfflX9hVT"
      },
      "source": [
        "!python train.py --inp-lang=$inp_lang --tar-lang=$tar_lang \\\n",
        "                 --batch-size=128 --hidden-units=128 --embedding-size=64 \\\n",
        "                 --epochs=1000 --train-mode=\"not_attention\" --test-split-size=0.1 \\\n",
        "                 --min-sentence=10 --max-sentence=14 \\\n",
        "                 --learning-rate=0.005 --bleu=True --debug=True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxASYx2MxLWF"
      },
      "source": [
        "#Use attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TofQ_4wj41TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c7907d-3271-4863-8700-6894f4161889"
      },
      "source": [
        "!python train.py --inp-lang=$inp_lang --tar-lang=$tar_lang \\\n",
        "                 --batch-size=128 --hidden-units=512 --embedding-size=256 \\\n",
        "                 --epochs=1000 --train-mode=\"attention\" --test-split-size=0.005 \\\n",
        "                 --min-sentence=0 --max-sentence=35 --debug=True \\\n",
        "                 --warmup-steps=150 --use-lr-schedule=True --bleu=True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 838/838 [07:15<00:00,  1.92it/s]\n",
            "\n",
            "=================================================================\n",
            "-----------------------------------------------------------------\n",
            "Input    :  <sos> the science behind a climate headline <eos>\n",
            "Predicted:  khoa học đằng sau một trận khí hậu <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "Target   :  <sos> khoa học đằng sau một tiêu đề về khí hậu <eos>\n",
            "-----------------------------------------------------------------\n",
            "Input    :  <sos> i apos d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper <eos>\n",
            "Predicted:  tôi muốn nói với các bạn về quy mô của khoa học nỗ lực nỗ lực của khoa học sẽ tiến vào các nguyên tắc <eos> <eos> <eos> nhìn thấy trong giấy <eos> <eos> <eos>\n",
            "Target   :  <sos> tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo <eos>\n",
            "-----------------------------------------------------------------\n",
            "Input    :  <sos> headlines that look like this when they have to do with climate change and headlines that look like this when they have to do with air quality or smog <eos>\n",
            "Predicted:  các tiêu đề trông giống như thế này khi họ phải làm việc thay đổi khí chất hoặc có thể trông giống như thế này khi họ phải làm việc với chất lượng hay không\n",
            "Target   :  <sos> có những dòng trông như thế này khi bàn về biến đổi khí hậu và như thế này khi nói về chất lượng không khí hay khói bụi <eos>\n",
            "-----------------------------------------------------------------\n",
            "Input    :  <sos> they are both two branches of the same field of atmospheric science <eos>\n",
            "Predicted:  cả hai đều hai phần trăm các hai đều cùng nhau tương tác khoa học <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "Target   :  <sos> cả hai đều là một nhánh của cùng một lĩnh vực trong ngành khoa học khí quyển <eos>\n",
            "-----------------------------------------------------------------\n",
            "Input    :  <sos> that report was written by 620 scientists from 40 countries <eos>\n",
            "Predicted:  báo cáo đó được viết bởi những nhà khoa học từ 40 quốc gia <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "Target   :  <sos> nghiên cứu được viết bởi 620 nhà khoa học từ 40 quốc gia khác nhau <eos>\n",
            "-----------------------------------------------------------------\n",
            "Input    :  <sos> they wrote almost a thousand pages on the topic <eos>\n",
            "Predicted:  họ viết gần 1000 trang trên chủ đề <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "Target   :  <sos> họ viết gần 1000 trang về chủ đề này <eos>\n",
            "-----------------------------------------------------------------\n",
            "Epoch 7 -- Loss: 31332.513671875 -- Bleu_score: 0.2836192680650839\n",
            "[INFO] Saved model in '/content/Seq2Seq/saved_models' direction!\n",
            "=================================================================\n",
            "\n",
            " 45% 380/838 [03:17<03:55,  1.95it/s]"
          ]
        }
      ]
    }
  ]
}