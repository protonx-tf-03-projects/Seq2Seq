"""
1. Preprocessing data
2. Encoder class:
    +) input: vocab_size(10.000), embedding: 1000, max_length: mean(all_sequences)
        - Embedding (sequence -> vector) (CBOW, Skip-gram,...)
    +) input: max_length: mean(all_sequences), embedding: 1000
        - 4_LSTM (GRU) -> output: (1000, 1)

3. Decoder class:
    - Bi-direction: <->
    - LSTM: -> input: (1000, 1): Đầu cuối
    - LSTM: -> input: (1000, 1): Cuối đầu
    - Dense: -> (80000, )
    - Softmax:

4. Training + evaluation:
    - Training:
        +) optimizer: SGD(without momentum): stochastic gradient descent - (Adam)
        +) loss: sparse_categorical_crossentropy
        +) metric: accuracy || BLEU = ?
    - Evaluation:
        +) metric: BLEU
"""

